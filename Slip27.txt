Q.1. Create a multiple linear regression model for house price dataset divide dataset
into train and test data while giving it to model and predict prices of house

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
data = {
'Area': [1500, 1800, 2400, 3000, 3500, 4000],
'Rooms': [3, 4, 4, 5, 5, 6],
'Age': [10, 15, 20, 25, 30, 35],
'Price': [400000, 450000, 600000, 650000, 700000, 750000] 
(Price)
}
df = pd.DataFrame(data)
X = df[['Area', 'Rooms', 'Age']] 
y = df['Price'] 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared (R2): {r2}")
new_house_data = np.array([[2500, 4, 15]]) 
predicted_price = model.predict(new_house_data)
print(f"Predicted Price for the new house: ${predicted_price[0]:,.2f}")

Q.2. Fit the simple linear regression and polynomial linear regression models to
Salary_positions.csv data. Find which one is more accurately fitting to the given data.
Also predict the salaries of level 11 and level 12 employees.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
df = pd.read_csv('Salary_positions.csv')
X = df['Level'].values.reshape(-1, 1) 
y = df['Salary'].values 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)
linear_regressor = LinearRegression()
linear_regressor.fit(X_train, y_train)
y_pred_linear = linear_regressor.predict(X_test)
poly = PolynomialFeatures(degree=4)
X_poly = poly.fit_transform(X_train) 
poly_regressor = LinearRegression()
poly_regressor.fit(X_poly, y_train)
X_test_poly = poly.transform(X_test) 
y_pred_poly = poly_regressor.predict(X_test_poly)
linear_r2 = r2_score(y_test, y_pred_linear)
linear_mse = mean_squared_error(y_test, y_pred_linear)
poly_r2 = r2_score(y_test, y_pred_poly)
poly_mse = mean_squared_error(y_test, y_pred_poly)
print(f"Simple Linear Regression R2: {linear_r2:.4f}")
print(f"Simple Linear Regression MSE: {linear_mse:.4f}")
print(f"Polynomial Linear Regression R2: {poly_r2:.4f}")
print(f"Polynomial Linear Regression MSE: {poly_mse:.4f}")
level_11 = np.array([[11]]) 
level_12 = np.array([[12]]) 
salary_11_linear = linear_regressor.predict(level_11)
salary_12_linear = linear_regressor.predict(level_12)
salary_11_poly = poly_regressor.predict(poly.transform(level_11))
salary_12_poly = poly_regressor.predict(poly.transform(level_12))
print(f"Predicted Salary for Level 11 (Simple Linear Regression):
{salary_11_linear[0]:,.2f}")
print(f"Predicted Salary for Level 12 (Simple Linear Regression):
{salary_12_linear[0]:,.2f}")
print(f"Predicted Salary for Level 11 (Polynomial Regression):
{salary_11_poly[0]:,.2f}")
print(f"Predicted Salary for Level 12 (Polynomial Regression):
{salary_12_poly[0]:,.2f}")
plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.scatter(X, y, color='red')
plt.plot(X, linear_regressor.predict(X), color='blue')
plt.title('Simple Linear Regression')
plt.xlabel('Level')
plt.ylabel('Salary')
plt.subplot(1, 2, 2)
plt.scatter(X, y, color='red')
plt.plot(np.arange(1, 13).reshape(-1, 1),
poly_regressor.predict(poly.transform(np.arange(1, 13).reshape(-1, 1))), color='blue')
plt.title('Polynomial Linear Regression')
plt.xlabel('Level')
plt.ylabel('Salary')
plt.tight_layout()
plt.show()