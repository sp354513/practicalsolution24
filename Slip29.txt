Q.1. Take iris flower dataset and reduce 4D data to 2D data using PCA. Then train the
model and predict new flower with given measurements.

import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
iris = datasets.load_iris()
X = iris.data 
y = iris.target 
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2,
random_state=42)
svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the SVM model with PCA-reduced data: {accuracy * 100:.2f}%")
new_flower = np.array([[5.1, 3.5, 1.4, 0.2]])
new_flower_scaled = scaler.transform(new_flower)
new_flower_pca = pca.transform(new_flower_scaled)
predicted_class = svm.predict(new_flower_pca)
predicted_class_name = iris.target_names[predicted_class][0]
print(f"Predicted flower species for the input data {new_flower[0]}:
{predicted_class_name}")

Q.2. Use K-means clustering model and classify the employees into various income
groups or clusters. Preprocess data if require (i.e. drop missing or null values). Use
elbow method and Silhouette Score to find value of k.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
df = pd.read_csv('employee_data.csv')
df.dropna(inplace=True)
X = df[['Income', 'Age']].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
values
inertia = []
k_range = range(1, 11)
for k in k_range:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_scaled)
inertia.append(kmeans.inertia_)
plt.figure(figsize=(8, 6))
plt.plot(k_range, inertia, marker='o', linestyle='-', color='b')
plt.title('Elbow Method to Find Optimal K')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia (Sum of Squared Distances)')
plt.show()
sil_scores = []
for k in k_range[1:]:
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(X_scaled)
score = silhouette_score(X_scaled, kmeans.labels_)
sil_scores.append(score)
plt.figure(figsize=(8, 6))
plt.plot(k_range[1:], sil_scores, marker='o', linestyle='-', color='g')
plt.title('Silhouette Score for Different K')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.show()
optimal_k = 3 
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
kmeans.fit(X_scaled)
df['Cluster'] = kmeans.labels_
print(f"Cluster Centers:\n{kmeans.cluster_centers_}")
print(f"Cluster Distribution:\n{df['Cluster'].value_counts()}")
plt.figure(figsize=(8, 6))
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df['Cluster'], cmap='viridis')
plt.title('Employee Clusters Based on Income and Age')
plt.xlabel('Income (Standardized)')
plt.ylabel('Age (Standardized)')
plt.show()
new_employee = np.array([[50000, 30]])
new_employee_scaled = scaler.transform(new_employee)
new_cluster = kmeans.predict(new_employee_scaled)
print(f"The new employee belongs to Cluster: {new_cluster[0]}")